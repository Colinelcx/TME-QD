{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME UE IAR: From Traditional EA to Quality-Diversity algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette séance de TME consiste à mettre en oeuvre des méthodes d'apprentissage de type \"direct policy search\" s'appuyant sur des algorithmes évolutionnistes. \n",
    "\n",
    "Ces algorithmes s'appuient sur des opérateurs de recherche stochastiques. Si vous lancez plusieurs fois une même expérience avec une graine aléatoire différente vous obtiendrez des résultats différents. Dans la mesure du possible et de la puissance de calcul que vous avez à disposition et s'il n'a pas été demandé explicitement de ne faire qu'une seule expérience, il est donc souhaitable de répéter les expériences plusieurs fois avant de conclure.\n",
    "\n",
    "Les cellules à compléter sont marquées <à compléter>.\n",
    "\n",
    "Vous prendrez soin de ne soumettre que les fichiers nécessaires (merci d'éviter les fichiers de log inutiles et de taille conséquente...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dépendances\n",
    "\n",
    "L'environnement `FastsimSimpleNavigation-v0` de gym_fastsim permet de lancer des expériences de navigation avec un robot à roues naviguant dans un labyrinthe. Il se présente sous la forme d'une bibliothèque en C++ (libfastsim), d'une interface en python (pyfastsim) et d'une interface gym (fastsim_gym). Ces trois bibliothèques vous sont fournies avec un README qui explique comment les installer. En bref:\n",
    "* libfastsim: `./waf configure` et `./waf build` (dépendance optionnelle SDL 1.2)\n",
    "* pyfastsim: `pip3 install .` (dépendances: compilateur compatible c++14, module pybind11 avec module de développement associé)\n",
    "* fastsim_gym: `pip3 install .` (dépendance: gym)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Code fourni\n",
    "\n",
    "Le code vous permettant de reproduire les expériences de Lehman et Stanley sur la recherche de nouveauté vous est fourni (ceux qui ont suivi l'UE robotique et apprentissage de M1 l'ont fait en TME l'an dernier).\n",
    "\n",
    "Contenu des fichiers fournis:\n",
    "* fixed_structure_nn_numpy.py: réseau de neurones à structures fixe qui servira de politique paramétrée\n",
    "* maze_plot.py: fonctions pour tracer l'espace comportemental associé aux expériences de Lehman et Stanley (navigation dans un labyrinthe)\n",
    "* plot.py: fonctions pour tracer des fronts de pareto\n",
    "\n",
    "Code à modifier/compléter:\n",
    "* ea_dps.py: c'est le fichier principal pour lancer une expérience \n",
    "* novelty_search.py: gestion d'un objectif de nouveauté\n",
    "* grid_management.py: gestion d'une grille pour suivre l'avancement de l'exploration et implémenter MAP-Elites\n",
    "\n",
    "Ce code inclut des facilités pour enregistrer des logs, sauvegarder des trajectoires et les tracer ensuite.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il n'y a rien à faire d'autre que d'exécuter cette cellule, \n",
    "# elle contient des imports qui vous seront utiles\n",
    "\n",
    "# Note: l'import d'un fichier ne se fait qu'une seule fois. Si vous modifiez ce fichier, \n",
    "# il vous faut redémarrer votre kernel si vous voulez prendre en compte les modifications.\n",
    "# vous pouvez éviter cela de la façon suivante: \n",
    "import importlib # une seule fois\n",
    "import plot # le module doit avoir été importé une première fois\n",
    "importlib.reload(plot) # cette ligne permet de charger la dernière version\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pour que les figures apparaissent directement dans le notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Comparaison des expériences de Fit, NS et Fit+NS\n",
    "\n",
    "Cette première partie vise à vous faire prendre en main le code de l'expérience de navigation dans un labyrinthe et ses variantes NS, FIT et FIT+NS. \n",
    "\n",
    "Vous regarderez attentivement le fichier ea_dps.py et vous le compléterez pour afficher un message chaque fois qu'une politique s'approche de la sortie plus que ce qui a été fait auparavant. A cette occasion, vous sauvegarderez la trajectoire de cet individu (vous devrez pour cela le réévaluer en mettant le paramètre dump à True) pour pouvoir la tracer ensuite dans les questions suivantes de ce notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Variante Fit\n",
    "\n",
    "Lancez quelques expériences avec la variante FIT et indiquez le nombre moyen de générations pour atteindre la sortie (avec un nombre maximum de générations de 200). Vous pouvez l'obtenir en regardant les fichiers info.log générés et en cherchant la première génération où apparait un 'exit_reached': 1.0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': 'bar', 'hello': 'world'}\n"
     ]
    }
   ],
   "source": [
    "#le code suivant permet d'interpréter une ligne contenant un dictionnaire, vous pouvez vous en inspirer pour lire les fichiers info.log \n",
    "# et extraire les valeurs de exit_reached.\n",
    "import ast\n",
    "\n",
    "\n",
    "# pour relire un dictionnaire depuis info.log, vous pourrez utiliser le code suivant:\n",
    "y = ast.literal_eval(\"{'foo' : 'bar', 'hello' : 'world'}\")\n",
    "print(str(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <à compléter>\n",
    "\n",
    "# indiquer ici la valeur moyenne trouvée "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracez les trajectoires générées par les individus qui ont fait progresser la fitness pendant une expérience. Vous pourrez utiliser la fonction plot_traj_file qui est dans le fichier maze_plot.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <à compléter>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Variante NS\n",
    "\n",
    "Mêmes questions avec la variante NS: lancez quelques expériences avec cette variante et indiquez le nombre moyen de générations pour atteindre la sortie (avec un nombre maximum de générations de 200). \n",
    "\n",
    "Tracez les trajectoires générées par les individus qui ont fait progresser la fitness pendant une expérience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <à compléter>\n",
    "\n",
    "# indiquer ici la valeur moyenne trouvée et compléter avec le code permettant de tracer les trajectoires.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Variante FIT+NS\n",
    "\n",
    "Mêmes questions avec la variante qui utilise 2 objectifs: Fitness et Novelty (variante FIT+NS). Lancez quelques expériences avec cette variante et indiquez le nombre moyen de générations pour atteindre la sortie (avec un nombre maximum de générations de 200). \n",
    "\n",
    "Tracez les trajectoires générées par les individus qui ont fait progresser la fitness pendant une expérience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <à compléter>\n",
    "\n",
    "# indiquer ici la valeur moyenne trouvée et compléter avec le code permettant de tracer les trajectoires.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Diversité des comportements générés\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La position finale de chaque point généré est enregistrée dans le fichier info.log (champ robot_pos). Tracez ces différents points sur une même figure pour une experience de NS, de FIT et de FIT+NS. Vous tracerez sur une figure l'ensemble des points générés par une expérience de chaque variante. Qu'en déduisez-vous sur la capacité d'exploration de chacun de ces algorithmes ? Vous pourrez le comparer à un échantillonnage aléatoire (il suffit de mettre 0 générations et pour mu le nombre d'échantillons souhaités)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <à compléter>\n",
    "\n",
    "\n",
    "# pour tracer un ensemble de points, vous pourrez utiliser maze_plot.plot_points(pts)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracez sur des figures séparées les points générés pour plusieurs générations successives de NS, FIT et FIT+NS (par exemple 90, 91, 92). Que constatez vous ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <à compléter>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Ajout d'une qualité locale\n",
    "\n",
    "L'ensemble des solutions générées peut être utilisé pour atteindre n'importe lequel des comportements atteignables, mais l'inconvénient de cette approche est que la notion de qualité est totalement absente du processus, or parmi les solutions générant un comportement donné, toutes ne se valent pas. Certaines sont plus intéressantes que d'autres parce qu'elle consomment moins d'énergie, qu'elles ne créent pas de collision, etc.\n",
    "\n",
    "Une solution pour prendre en compte un tel critère de qualité consiste à utiliser, à côté de l'objectif de nouveauté, un objectif de performance. Définir cet objectif comme une pression globale est contreproductif, car pour éviter des collisions ou minimiser la consommation d'énergie, il suffit de ne pas bouger... Pour rendre cette pression plus intéressante, il faut en faire un objectif non pas global, mais local.\n",
    "\n",
    "Pour cela, on peut suivre l'approche proposée par Lehman et Stanley [1]: on compare la fitness de l'individu considéré avec celle de ses plus proches voisins (qui sont déjà déterminés pour le calcul de nouveauté). L'objectif de compétition locale vaut le nombre de voisins dont la fitness est inférieure.\n",
    "\n",
    "Complétez le code de novelty_search.py pour que la fonction de calcul de nouveauté renvoie la nouveauté et l'objectif de compétition locale. Pour cela, vous devrez garder dans l'archive la liste des fitness des points ajoutés.\n",
    "\n",
    "Utilisez cette nouvelle version pour générer des politiques qui permettent d'atteindre les différentes positions du labyrinthe en minimisant le nombre de collision du robot avec les murs, par exemple.\n",
    "\n",
    "Vous tracerez les trajectoires des meilleurs individus générés.\n",
    "\n",
    "* [1] Lehman, J., & Stanley, K. O. (2011). Evolving a diversity of virtual creatures through novelty search and local competition. In Proceedings of GECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <à compléter>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 \"Illuminer\" l'espace exploré\n",
    "\n",
    "### 5.1 Quantifier l'espace comportemental exploré"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez une grille dans l'espace comportemental qui va vous permettre de mesurer l'espace exploré. Découpez l'espace en cases (vous ignorerez les murs pour simplifier) et écrivez une fonction permettant de placer un individu dans case correspondant à son descripteur comportemental une fois qu'il a été évalué. Il n'y aura qu'un seul individu par case. Lorsque vous tentez d'ajouter un individu dans une case, si elle est déjà remplie, le nouvel individu remplacera l'ancien si sa fitness est plus élevée. \n",
    "\n",
    "Cette grille est (pour l'instant) indépendante de l'algorithme d'apprentissage. Elle vise simplement à mesurer la capacité de ce dernier à explorer cet espace et à retrouver facilement, si besoin, une politique efficace permettant d'atteindre un comportement donné.\n",
    "\n",
    "Vous mesurerez la couverture de votre exploration (pourcentage de cellules explorées). Utilisez une grille de 100x100 cases sur l'expérience de navigation dans le labyrinthe et déterminez la couverture pour les trois variantes: FIT, NS, FIT+NS et NSLC (vous vous contenterez d'une seule expérience).\n",
    "\n",
    "A la fin de votre expérience, vous afficherez le nombre de cellules que vous pouvez atteindre sans collision. Vous tracerez les trajectoires associées à quelques unes d'entre elles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <à compléter>\n",
    "\n",
    "# indiquez ici les résultats trouvés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 OPTION: MAP-Elites\n",
    "\n",
    "#### 5.2.1 Implémentation de MAP-Elites\n",
    "\n",
    "La grille définie à la question précédente permet de définir un algorithme très simple: MAP-Elites [1]. Dans cet algorithme, la sélection s'appuie sur la grille. La génération d'un nouvel individu consiste à tirer aléatoirement un (si mutation uniquement) ou deux individus (si croisement) dans la grille puis à appliquer l'opérateur génétique de mutation ou de croisement. Après évaluation, on tente d'ajouter cet individu dans la grille et on \n",
    "\n",
    "Utilisez cet algorithme sur la tâche de navigation et indiquer le nombre de cellules atteignables sans collision. Vous pourrez tracer des trajectoires associées à quelques unes d'entre elles.\n",
    "\n",
    "\n",
    "MAP-Elites est un algorithme très simple. Le prix à payer est qu'il est bien plus lent que Novelty search pour couvrir l'espace atteignable. Ses performances peuvent être améliorées si le génotype est de plus petite taille. \n",
    "\n",
    "* [1] Mouret, J. B., & Clune, J. (2015). Illuminating search spaces by mapping elites. arXiv preprint arXiv:1504.04909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <à compléter>\n",
    "\n",
    "# indiquez ici les résultats trouvés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Variantes de MAP-Elites\n",
    "\n",
    "MAP-Elites peut aussi être amélioré avec des stratégies de choix des parents qui ne sont plus uniformes sur toute la grille, mais biaisées pour favoriser les cellules isolées ou les individus dont les descendants ont réussi à remplir des cellules (score de \"curiosité\" [1]). \n",
    "\n",
    "* [1] Cully, A., & Demiris, Y. (2017). Quality and diversity optimization: A unifying modular framework. IEEE Transactions on Evolutionary Computation, 22(2), 245-259."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <à compléter>\n",
    "\n",
    "# indiquez ici les résultats trouvés"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
